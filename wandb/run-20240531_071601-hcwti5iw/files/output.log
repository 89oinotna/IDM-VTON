/root/miniconda3/envs/idm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
{'thresholding', 'clip_sample_range', 'variance_type', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.
/root/miniconda3/envs/idm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
The config attributes {'decay': 0.9999, 'inv_gamma': 1.0, 'min_decay': 0.0, 'optimization_step': 37000, 'power': 0.6666666666666666, 'update_after_step': 0, 'use_ema_warmup': False} were passed to UNet2DConditionModel, but are not expected and will be ignored. Please verify your config.json configuration file.
{'reverse_transformer_layers_per_block', 'dropout'} was not found in config. Values will be initialized to default values.
{'dropout', 'addition_embed_type', 'reverse_transformer_layers_per_block', 'attention_type'} was not found in config. Values will be initialized to default values.
Some weights of the model checkpoint were not used when initializing UNet2DConditionModel:
 ['add_embedding.linear_1.bias, add_embedding.linear_1.weight, add_embedding.linear_2.bias, add_embedding.linear_2.weight']
{'image_encoder'} was not found in config. Values will be initialized to default values.
Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 425.07it/s]






























100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [02:15<00:00,  4.53s/it]
Global_step:  0
Images generated!
Images generated!
Images generated!
Images generated!
Images generated!
Images generated!
Images generated!
Images generated!
Images generated!
Images generated!
Images generated!
Images generated!
Images generated!
Images generated!
Images generated!
Images generated!






























100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [02:16<00:00,  4.56s/it]
Traceback (most recent call last):
  File "/notebooks/ayna/working_repo/IDM-VTON/train.py", line 337, in <module>
    main()
  File "/notebooks/ayna/working_repo/IDM-VTON/train.py", line 334, in main
    train(args, train_dataloader, model, unet, image_encoder, optimizer, accelerator)
  File "/notebooks/ayna/working_repo/IDM-VTON/train.py", line 194, in train
    images = model(
  File "/root/miniconda3/envs/idm/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/notebooks/ayna/working_repo/IDM-VTON/src/tryon_pipeline.py", line 1876, in __call__
    image = self.vae.decode(latents / self.vae.config.scaling_factor, return_dict=False)[0]
  File "/root/miniconda3/envs/idm/lib/python3.10/site-packages/diffusers/utils/accelerate_utils.py", line 46, in wrapper
    return method(self, *args, **kwargs)
  File "/root/miniconda3/envs/idm/lib/python3.10/site-packages/diffusers/models/autoencoders/autoencoder_kl.py", line 304, in decode
    decoded = self._decode(z).sample
  File "/root/miniconda3/envs/idm/lib/python3.10/site-packages/diffusers/models/autoencoders/autoencoder_kl.py", line 275, in _decode
    dec = self.decoder(z)
  File "/root/miniconda3/envs/idm/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/idm/lib/python3.10/site-packages/diffusers/models/autoencoders/vae.py", line 338, in forward
    sample = up_block(sample, latent_embeds)
  File "/root/miniconda3/envs/idm/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/idm/lib/python3.10/site-packages/diffusers/models/unet_2d_blocks.py", line 2535, in forward
    hidden_states = upsampler(hidden_states)
  File "/root/miniconda3/envs/idm/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/idm/lib/python3.10/site-packages/diffusers/models/upsampling.py", line 184, in forward
    hidden_states = self.conv(hidden_states, scale)
  File "/root/miniconda3/envs/idm/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/idm/lib/python3.10/site-packages/diffusers/models/lora.py", line 358, in forward
    return F.conv2d(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.00 GiB (GPU 0; 47.54 GiB total capacity; 31.79 GiB already allocated; 95.12 MiB free; 46.09 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF