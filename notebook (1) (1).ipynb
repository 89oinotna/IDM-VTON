{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42303198-b0ed-4ac7-9c41-073dac16627f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'IDM-VTON'...\n",
      "remote: Enumerating objects: 2142, done.\u001b[K\n",
      "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
      "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
      "remote: Total 2142 (delta 41), reused 34 (delta 29), pack-reused 2084\u001b[K\n",
      "Receiving objects: 100% (2142/2142), 55.25 MiB | 73.19 MiB/s, done.\n",
      "Resolving deltas: 100% (715/715), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/89oinotna/IDM-VTON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b4e01d8-d579-4494-9b28-b995cd3f232a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/IDM-VTON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd IDM-VTON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "596327a9-64d4-481d-8b45-7df12bf18dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91be7b8b-0897-4a16-b5a6-1835c8f95a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (4.41.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2.2.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.17.0)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.26.3)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.13.1)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (0.23.2)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.9.0.80)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (10.2.0)\n",
      "Collecting diffusers==0.25.1 (from -r requirements.txt (line 10))\n",
      "  Downloading diffusers-0.25.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.30.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (3.9.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (4.66.4)\n",
      "Requirement already satisfied: config in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (0.5.1)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.8.0)\n",
      "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (1.18.0)\n",
      "Requirement already satisfied: basicsr in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (1.4.2)\n",
      "Requirement already satisfied: av in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (12.1.0)\n",
      "Requirement already satisfied: fvcore in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (0.1.5.post20221221)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (3.0.0)\n",
      "Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (2.3.0)\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 23)) (2.0.7)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.1->-r requirements.txt (line 10)) (7.1.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.1->-r requirements.txt (line 10)) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.1->-r requirements.txt (line 10)) (0.23.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.1->-r requirements.txt (line 10)) (2024.5.15)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.1->-r requirements.txt (line 10)) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.1->-r requirements.txt (line 10)) (0.4.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (0.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 2)) (12.3.101)\n",
      "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 7)) (2.34.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 7)) (2024.5.22)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 7)) (0.4)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 12)) (5.9.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 13)) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 13)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 13)) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 13)) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->-r requirements.txt (line 13)) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 13)) (2.8.2)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime->-r requirements.txt (line 17)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime->-r requirements.txt (line 17)) (24.3.25)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime->-r requirements.txt (line 17)) (4.25.3)\n",
      "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from basicsr->-r requirements.txt (line 18)) (2.4.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from basicsr->-r requirements.txt (line 18)) (1.0.0)\n",
      "Requirement already satisfied: lmdb in /usr/local/lib/python3.10/dist-packages (from basicsr->-r requirements.txt (line 18)) (1.4.1)\n",
      "Requirement already satisfied: tb-nightly in /usr/local/lib/python3.10/dist-packages (from basicsr->-r requirements.txt (line 18)) (2.17.0a20240602)\n",
      "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from basicsr->-r requirements.txt (line 18)) (0.40.2)\n",
      "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from fvcore->-r requirements.txt (line 20)) (0.1.8)\n",
      "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from fvcore->-r requirements.txt (line 20)) (2.4.0)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fvcore->-r requirements.txt (line 20)) (0.9.0)\n",
      "Requirement already satisfied: iopath>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from fvcore->-r requirements.txt (line 20)) (0.1.10)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf->-r requirements.txt (line 22)) (4.9.3)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath>=0.1.7->fvcore->-r requirements.txt (line 20)) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 13)) (1.16.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime->-r requirements.txt (line 17)) (10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/lib/python3/dist-packages (from importlib-metadata->diffusers==0.25.1->-r requirements.txt (line 10)) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 2)) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.25.1->-r requirements.txt (line 10)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.25.1->-r requirements.txt (line 10)) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.25.1->-r requirements.txt (line 10)) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.25.1->-r requirements.txt (line 10)) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr->-r requirements.txt (line 18)) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr->-r requirements.txt (line 18)) (1.64.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr->-r requirements.txt (line 18)) (3.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr->-r requirements.txt (line 18)) (69.0.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr->-r requirements.txt (line 18)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr->-r requirements.txt (line 18)) (3.0.3)\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->basicsr->-r requirements.txt (line 18)) (4.2.0)\n",
      "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->basicsr->-r requirements.txt (line 18)) (2.0.1)\n",
      "Downloading diffusers-0.25.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: diffusers\n",
      "  Attempting uninstall: diffusers\n",
      "    Found existing installation: diffusers 0.28.0\n",
      "    Uninstalling diffusers-0.28.0:\n",
      "      Successfully uninstalled diffusers-0.28.0\n",
      "Successfully installed diffusers-0.25.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9bef6b4-bac6-47bc-9dc6-a3cbf8710eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt/densepose/mode 100%[===================>] 243.91M  95.8MB/s    in 2.5s    \n",
      "ckpt/humanparsing/p 100%[===================>] 254.50M   109MB/s    in 2.3s    \n",
      "ckpt/humanparsing/p 100%[===================>] 254.50M  96.5MB/s    in 2.6s    \n",
      "ckpt/openpose/ckpts 100%[===================>] 199.57M  64.3MB/s    in 3.2s    \n"
     ]
    }
   ],
   "source": [
    "!wget -q --show-progress --progress=bar:force:noscroll -O ckpt/densepose/model_final_162be9.pkl https://huggingface.co/camenduru/IDM-VTON/resolve/main/densepose/model_final_162be9.pkl\n",
    "!wget -q --show-progress --progress=bar:force:noscroll -O ckpt/humanparsing/parsing_atr.onnx https://huggingface.co/camenduru/IDM-VTON/resolve/main/humanparsing/parsing_atr.onnx\n",
    "!wget -q --show-progress --progress=bar:force:noscroll -O ckpt/humanparsing/parsing_lip.onnx https://huggingface.co/camenduru/IDM-VTON/resolve/main/humanparsing/parsing_lip.onnx\n",
    "!wget -q --show-progress --progress=bar:force:noscroll -O ckpt/openpose/ckpts/body_pose_model.pth https://huggingface.co/camenduru/IDM-VTON/resolve/main/openpose/ckpts/body_pose_model.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "206bb14f-5104-49fa-ab65-3af97cb15a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-4.32.2-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting altair<6.0,>=4.2.0 (from gradio)\n",
      "  Downloading altair-5.3.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting fastapi (from gradio)\n",
      "  Downloading fastapi-0.111.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gradio-client==0.17.0 (from gradio)\n",
      "  Downloading gradio_client-0.17.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.2)\n",
      "Collecting importlib-resources<7.0,>=1.3 (from gradio)\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.9.0)\n",
      "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.3)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
      "Collecting pandas<3.0,>=1.0 (from gradio)\n",
      "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.2.0)\n",
      "Collecting pydantic>=2.0 (from gradio)\n",
      "  Downloading pydantic-2.7.2-py3-none-any.whl.metadata (108 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.5/108.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from gradio)\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
      "Collecting ruff>=0.2.2 (from gradio)\n",
      "  Downloading ruff-0.4.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.0)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.30.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.17.0->gradio) (2024.2.0)\n",
      "Collecting websockets<12.0,>=10.0 (from gradio-client==0.17.0->gradio)\n",
      "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.21.1)\n",
      "Collecting toolz (from altair<6.0,>=4.2.0->gradio)\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (4.2.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.2)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib~=3.0->gradio) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas<3.0,>=1.0->gradio)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3.0,>=1.0->gradio)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>=2.0->gradio)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.18.3 (from pydantic>=2.0->gradio)\n",
      "  Downloading pydantic_core-2.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting click>=8.0.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
      "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n",
      "  Downloading fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio)\n",
      "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Collecting email_validator>=2.0.0 (from fastapi->gradio)\n",
      "  Downloading email_validator-2.1.1-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n",
      "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.33.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.17.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.17.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.0)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.12.0->fastapi->gradio)\n",
      "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0->fastapi->gradio)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0->fastapi->gradio)\n",
      "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0->fastapi->gradio)\n",
      "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading gradio-4.32.2-py3-none-any.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-0.17.0-py3-none-any.whl (316 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.3/316.3 kB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading altair-5.3.0-py3-none-any.whl (857 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m857.8/857.8 kB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.7.2-py3-none-any.whl (409 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.5/409.5 kB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading ruff-0.4.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
      "Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m110.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: ffmpy\n",
      "  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=a6b87fd4270c36215ab4531541850523341d45aa38d0bb58e29bec872a2d621b\n",
      "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
      "Successfully built ffmpy\n",
      "Installing collected packages: pytz, pydub, ffmpy, websockets, uvloop, ujson, tzdata, toolz, tomlkit, shellingham, semantic-version, ruff, python-multipart, python-dotenv, pydantic-core, orjson, mdurl, importlib-resources, httptools, dnspython, click, annotated-types, aiofiles, watchfiles, uvicorn, starlette, pydantic, pandas, markdown-it-py, email_validator, rich, gradio-client, typer, altair, fastapi-cli, fastapi, gradio\n",
      "Successfully installed aiofiles-23.2.1 altair-5.3.0 annotated-types-0.7.0 click-8.1.7 dnspython-2.6.1 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 gradio-4.32.2 gradio-client-0.17.0 httptools-0.6.1 importlib-resources-6.4.0 markdown-it-py-3.0.0 mdurl-0.1.2 orjson-3.10.3 pandas-2.2.2 pydantic-2.7.2 pydantic-core-2.18.3 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 pytz-2024.1 rich-13.7.1 ruff-0.4.7 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.37.2 tomlkit-0.12.0 toolz-0.12.1 typer-0.12.3 tzdata-2024.1 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-11.0.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f1a4732-219b-482d-a9b9-52e9118c9cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "The config attributes {'decay': 0.9999, 'inv_gamma': 1.0, 'min_decay': 0.0, 'optimization_step': 37000, 'power': 0.6666666666666666, 'update_after_step': 0, 'use_ema_warmup': False} were passed to UNet2DConditionModel, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "/usr/local/lib/python3.10/dist-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "Some weights of the model checkpoint were not used when initializing UNet2DConditionModel: \n",
      " ['add_embedding.linear_1.bias, add_embedding.linear_1.weight, add_embedding.linear_2.bias, add_embedding.linear_2.weight']\n",
      "Loading pipeline components...: 100%|███████████| 8/8 [00:00<00:00, 1819.36it/s]\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://850195835cfe3667e9.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.56s/it]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.48s/it]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|███████████████████████████████████████████| 30/30 [00:06<00:00,  4.97it/s]\n",
      "^C\n",
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7860 <> https://850195835cfe3667e9.gradio.live\n"
     ]
    }
   ],
   "source": [
    "!python gradio_demo/app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38715b02-0ad9-4f7e-8839-7c6c03203771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md                      environment.yaml   \u001b[0m\u001b[01;34mpreprocess\u001b[0m/\n",
      "\u001b[01;34massets\u001b[0m/                        \u001b[01;34mgradio_demo\u001b[0m/       requirements.txt\n",
      "batch.py                       inference.py       \u001b[01;34msrc\u001b[0m/\n",
      "\u001b[01;34mckpt\u001b[0m/                          inference.sh       train.py\n",
      "\u001b[01;34mconfigs\u001b[0m/                       inference_dc.py    vitonhd_test_tagged.json\n",
      "\u001b[01;34mdata_prep\u001b[0m/                     inference_orig.py  vitonhd_train_tagged.json\n",
      "deepfashion_train_tagged.json  \u001b[01;34mip_adapter\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db9e6080-6baa-4706-ba9f-5a1f21b3fc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md                      environment.yaml   \u001b[0m\u001b[01;34mpreprocess\u001b[0m/\n",
      "\u001b[01;34massets\u001b[0m/                        \u001b[01;34mgradio_demo\u001b[0m/       requirements.txt\n",
      "batch.py                       inference.py       \u001b[01;34msrc\u001b[0m/\n",
      "\u001b[01;34mckpt\u001b[0m/                          inference.sh       train.py\n",
      "\u001b[01;34mconfigs\u001b[0m/                       inference_dc.py    vitonhd_test_tagged.json\n",
      "\u001b[01;34mdata_prep\u001b[0m/                     inference_orig.py  vitonhd_train_tagged.json\n",
      "deepfashion_train_tagged.json  \u001b[01;34mip_adapter\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b287e2f-5826-4b8a-a3cd-41a65e3eb891",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'detectron2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio_demo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils_mask\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_mask_location\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio_demo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m apply_net\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpreprocess\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhumanparsing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrun_parsing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Parsing\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpreprocess\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenpose\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrun_openpose\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenPose\n",
      "File \u001b[0;32m/workspace/IDM-VTON/gradio_demo/apply_net.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, ClassVar, Dict, List\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdetectron2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CfgNode, get_cfg\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdetectron2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdetection_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_image\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdetectron2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdefaults\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DefaultPredictor\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'detectron2'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "from src.tryon_pipeline import StableDiffusionXLInpaintPipeline as TryonPipeline\n",
    "from src.unet_hacked_garmnet import UNet2DConditionModel as UNet2DConditionModel_ref\n",
    "from src.unet_hacked_tryon import UNet2DConditionModel\n",
    "from transformers import (\n",
    "    CLIPImageProcessor,\n",
    "    CLIPVisionModelWithProjection,\n",
    "    CLIPTextModel,\n",
    "    CLIPTextModelWithProjection,\n",
    ")\n",
    "from diffusers import DDPMScheduler,AutoencoderKL\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from gradio_demo.utils_mask import get_mask_location\n",
    "from torchvision import transforms\n",
    "from gradio_demo import apply_net\n",
    "from preprocess.humanparsing.run_parsing import Parsing\n",
    "from preprocess.openpose.run_openpose import OpenPose\n",
    "from detectron2.data.detection_utils import convert_PIL_to_numpy,_apply_exif_orientation\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def pil_to_binary_mask(pil_image, threshold=0):\n",
    "    np_image = np.array(pil_image)\n",
    "    grayscale_image = Image.fromarray(np_image).convert(\"L\")\n",
    "    binary_mask = np.array(grayscale_image) > threshold\n",
    "    mask = np.zeros(binary_mask.shape, dtype=np.uint8)\n",
    "    for i in range(binary_mask.shape[0]):\n",
    "        for j in range(binary_mask.shape[1]):\n",
    "            if binary_mask[i,j] == True :\n",
    "                mask[i,j] = 1\n",
    "    mask = (mask*255).astype(np.uint8)\n",
    "    output_mask = Image.fromarray(mask)\n",
    "    return output_mask\n",
    "\n",
    "\n",
    "base_path = 'yisol/IDM-VTON'\n",
    "example_path = \"./example\"\n",
    "\n",
    "unet = UNet2DConditionModel.from_pretrained(\n",
    "    base_path,\n",
    "    subfolder=\"unet\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "unet.requires_grad_(False)\n",
    "tokenizer_one = AutoTokenizer.from_pretrained(\n",
    "    base_path,\n",
    "    subfolder=\"tokenizer\",\n",
    "    revision=None,\n",
    "    use_fast=False,\n",
    ")\n",
    "tokenizer_two = AutoTokenizer.from_pretrained(\n",
    "    base_path,\n",
    "    subfolder=\"tokenizer_2\",\n",
    "    revision=None,\n",
    "    use_fast=False,\n",
    ")\n",
    "noise_scheduler = DDPMScheduler.from_pretrained(base_path, subfolder=\"scheduler\")\n",
    "\n",
    "text_encoder_one = CLIPTextModel.from_pretrained(\n",
    "    base_path,\n",
    "    subfolder=\"text_encoder\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "text_encoder_two = CLIPTextModelWithProjection.from_pretrained(\n",
    "    base_path,\n",
    "    subfolder=\"text_encoder_2\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "image_encoder = CLIPVisionModelWithProjection.from_pretrained(\n",
    "    base_path,\n",
    "    subfolder=\"image_encoder\",\n",
    "    torch_dtype=torch.float16,\n",
    "    )\n",
    "vae = AutoencoderKL.from_pretrained(base_path,\n",
    "                                    subfolder=\"vae\",\n",
    "                                    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "# \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "UNet_Encoder = UNet2DConditionModel_ref.from_pretrained(\n",
    "    base_path,\n",
    "    subfolder=\"unet_encoder\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "parsing_model = Parsing(0)\n",
    "openpose_model = OpenPose(0)\n",
    "\n",
    "UNet_Encoder.requires_grad_(False)\n",
    "image_encoder.requires_grad_(False)\n",
    "vae.requires_grad_(False)\n",
    "unet.requires_grad_(False)\n",
    "text_encoder_one.requires_grad_(False)\n",
    "text_encoder_two.requires_grad_(False)\n",
    "tensor_transfrom = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.5], [0.5]),\n",
    "            ]\n",
    "    )\n",
    "\n",
    "pipe = TryonPipeline.from_pretrained(\n",
    "        base_path,\n",
    "        unet=unet,\n",
    "        vae=vae,\n",
    "        feature_extractor= CLIPImageProcessor(),\n",
    "        text_encoder = text_encoder_one,\n",
    "        text_encoder_2 = text_encoder_two,\n",
    "        tokenizer = tokenizer_one,\n",
    "        tokenizer_2 = tokenizer_two,\n",
    "        scheduler = noise_scheduler,\n",
    "        image_encoder=image_encoder,\n",
    "        torch_dtype=torch.float16,\n",
    ")\n",
    "pipe.unet_encoder = UNet_Encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5ce4dfa-6bec-4ce6-96fa-91a3d5a8aefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def start_tryon(dict, garm_img, garment_des, is_checked, is_checked_crop, denoise_steps, seed):\n",
    "    inference_times = {}\n",
    "\n",
    "    # Measure time for model loading\n",
    "    start_time = time.time()\n",
    "    openpose_model.preprocessor.body_estimation.model.to(device)\n",
    "    pipe.to(device)\n",
    "    pipe.unet_encoder.to(device)\n",
    "    inference_times['model_loading'] = round(time.time() - start_time,3)\n",
    "\n",
    "    # Image preprocessing\n",
    "    start_time = time.time()\n",
    "    garm_img = garm_img.convert(\"RGB\").resize((768,1024))\n",
    "    human_img_orig = dict.convert(\"RGB\")\n",
    "    if is_checked_crop:\n",
    "        width, height = human_img_orig.size\n",
    "        target_width = int(min(width, height * (3 / 4)))\n",
    "        target_height = int(min(height, width * (4 / 3)))\n",
    "        left = (width - target_width) / 2\n",
    "        top = (height - target_height) / 2\n",
    "        right = (width + target_width) / 2\n",
    "        bottom = (height + target_height) / 2\n",
    "        cropped_img = human_img_orig.crop((left, top, right, bottom))\n",
    "        crop_size = cropped_img.size\n",
    "        human_img = cropped_img.resize((768,1024))\n",
    "    else:\n",
    "        human_img = human_img_orig.resize((768,1024))\n",
    "    inference_times['image_preprocessing'] = round(time.time() - start_time,3)\n",
    "\n",
    "    # Keypoint extraction or mask generation\n",
    "    start_time = time.time()\n",
    "    if is_checked:\n",
    "        keypoints = openpose_model(human_img.resize((384,512)))\n",
    "        model_parse, _ = parsing_model(human_img.resize((384,512)))\n",
    "        mask, mask_gray = get_mask_location('hd', \"upper_body\", model_parse, keypoints)\n",
    "        mask = mask.resize((768,1024))\n",
    "    else:\n",
    "        mask = pil_to_binary_mask(dict['layers'][0].convert(\"RGB\").resize((768, 1024)))\n",
    "    mask_gray = (1-transforms.ToTensor()(mask)) * tensor_transfrom(human_img)\n",
    "    mask_gray = to_pil_image((mask_gray+1.0)/2.0)\n",
    "    inference_times['keypoint_mask_generation'] = round(time.time() - start_time,3)\n",
    "\n",
    "    # DensePose model inference\n",
    "    start_time = time.time()\n",
    "    human_img_arg = _apply_exif_orientation(human_img.resize((384,512)))\n",
    "    human_img_arg = convert_PIL_to_numpy(human_img_arg, format=\"BGR\")\n",
    "    args = apply_net.create_argument_parser().parse_args(('show', './configs/densepose_rcnn_R_50_FPN_s1x.yaml', './ckpt/densepose/model_final_162be9.pkl', 'dp_segm', '-v', '--opts', 'MODEL.DEVICE', 'cuda'))\n",
    "    pose_img = args.func(args, human_img_arg)\n",
    "    pose_img = pose_img[:,:,::-1]\n",
    "    pose_img = Image.fromarray(pose_img).resize((768,1024))\n",
    "    inference_times['densepose_inference'] = round(time.time() - start_time,3)\n",
    "\n",
    "    # Image generation\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast():\n",
    "            with torch.no_grad():\n",
    "                prompt = \"model is wearing \" + garment_des\n",
    "                negative_prompt = \"monochrome, lowres, bad anatomy, worst quality, low quality\"\n",
    "                with torch.inference_mode():\n",
    "                    (prompt_embeds, negative_prompt_embeds, pooled_prompt_embeds, negative_pooled_prompt_embeds) = pipe.encode_prompt(\n",
    "                        prompt,\n",
    "                        num_images_per_prompt=1,\n",
    "                        do_classifier_free_guidance=True,\n",
    "                        negative_prompt=negative_prompt,\n",
    "                    )\n",
    "                    prompt = \"a photo of \" + garment_des\n",
    "                    negative_prompt = \"monochrome, lowres, bad anatomy, worst quality, low quality\"\n",
    "                    if not isinstance(prompt, list):\n",
    "                        prompt = [prompt] * 1\n",
    "                    if not isinstance(negative_prompt, list):\n",
    "                        negative_prompt = [negative_prompt] * 1\n",
    "                    with torch.inference_mode():\n",
    "                        (prompt_embeds_c, _, _, _) = pipe.encode_prompt(\n",
    "                            prompt,\n",
    "                            num_images_per_prompt=1,\n",
    "                            do_classifier_free_guidance=False,\n",
    "                            negative_prompt=negative_prompt,\n",
    "                        )\n",
    "\n",
    "                    pose_img = tensor_transfrom(pose_img).unsqueeze(0).to(device, torch.float16)\n",
    "                    garm_tensor = tensor_transfrom(garm_img).unsqueeze(0).to(device, torch.float16)\n",
    "                    generator = torch.Generator(device).manual_seed(seed) if seed is not None else None\n",
    "                    images = pipe(\n",
    "                        prompt_embeds=prompt_embeds.to(device, torch.float16),\n",
    "                        negative_prompt_embeds=negative_prompt_embeds.to(device, torch.float16),\n",
    "                        pooled_prompt_embeds=pooled_prompt_embeds.to(device, torch.float16),\n",
    "                        negative_pooled_prompt_embeds=negative_pooled_prompt_embeds.to(device, torch.float16),\n",
    "                        num_inference_steps=denoise_steps,\n",
    "                        generator=generator,\n",
    "                        strength=1.0,\n",
    "                        pose_img=pose_img.to(device, torch.float16),\n",
    "                        text_embeds_cloth=prompt_embeds_c.to(device, torch.float16),\n",
    "                        cloth=garm_tensor.to(device, torch.float16),\n",
    "                        mask_image=mask,\n",
    "                        image=human_img,\n",
    "                        height=1024,\n",
    "                        width=768,\n",
    "                        ip_adapter_image=garm_img.resize((768,1024)),\n",
    "                        guidance_scale=2.0,\n",
    "                    )[0]\n",
    "    inference_times['image_generation'] = round(time.time() - start_time,3)\n",
    "\n",
    "    # Final image processing\n",
    "    start_time = time.time()\n",
    "    if is_checked_crop:\n",
    "        out_img = images[0].resize(crop_size)\n",
    "        human_img_orig.paste(out_img, (int(left), int(top)))\n",
    "        final_result = human_img_orig\n",
    "    else:\n",
    "        final_result = images[0]\n",
    "    return final_result, mask_gray, inference_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "41bb8765-fbd6-436b-adf4-dfd5c0a2e4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.75s/it]\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.30s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0aaae36ea64e55931a4e8ad9c95d95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 22.184470891952515 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.98s/it]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.21s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209a45f746354a99bb32db824e13826d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 22.312401056289673 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.94s/it]\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.30s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5c96c4079342f2a777f7f8d8164b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 25.52422261238098 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.88s/it]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.59s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0845bac305d844c2bf905071df223cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 23.816582202911377 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.43s/it]\n",
      "100%|██████████| 1/1 [00:09<00:00,  9.29s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f447f6012e5480ea994ed7a9ddceb5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 24.839121341705322 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.66s/it]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.50s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883112a461d94a558aa868469ab466a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 22.48157811164856 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.12s/it]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.91s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14317a7de3354efbb1a7fe895862c3a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 24.39935326576233 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.58s/it]\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.69s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed67b63185d4d6a89d71475e2ec0c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 21.441888093948364 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.36s/it]\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.19s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c986b62cbf5c42f588a43f3fa1bc60d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 23.69720435142517 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.06s/it]\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.39s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4df1c9ec4754813acd9d4632506154f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 21.675752639770508 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "execution_times = []\n",
    "for i in range(10):\n",
    "    start_time = time.time()\n",
    "    human_img_orig = Image.open(\"gradio_demo/example/human/foto_mia.jpg\")\n",
    "    garm_img = Image.open(\"gradio_demo/example/cloth/09163_00.jpg\")\n",
    "    out = start_tryon(human_img_orig, garm_img, \"\", True, False, 30, 23)\n",
    "    total_time = time.time() - start_time\n",
    "    print(\"--- %s seconds ---\" % (total_time))\n",
    "    out[2]['total'] = round(total_time, 3)\n",
    "    execution_times.append(out[2])\n",
    "df = pd.DataFrame(execution_times)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1a950503-8649-41b2-87b4-a599df2106f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_loading</th>\n",
       "      <th>image_preprocessing</th>\n",
       "      <th>keypoint_mask_generation</th>\n",
       "      <th>densepose_inference</th>\n",
       "      <th>image_generation</th>\n",
       "      <th>final_image_processing</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.070</td>\n",
       "      <td>0.023</td>\n",
       "      <td>13.368</td>\n",
       "      <td>1.042</td>\n",
       "      <td>7.678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.047</td>\n",
       "      <td>0.023</td>\n",
       "      <td>13.514</td>\n",
       "      <td>1.062</td>\n",
       "      <td>7.665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.047</td>\n",
       "      <td>0.022</td>\n",
       "      <td>16.543</td>\n",
       "      <td>1.102</td>\n",
       "      <td>7.809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.025</td>\n",
       "      <td>14.877</td>\n",
       "      <td>1.130</td>\n",
       "      <td>7.728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.047</td>\n",
       "      <td>0.022</td>\n",
       "      <td>16.047</td>\n",
       "      <td>1.051</td>\n",
       "      <td>7.671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.047</td>\n",
       "      <td>0.022</td>\n",
       "      <td>13.458</td>\n",
       "      <td>1.147</td>\n",
       "      <td>7.806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.054</td>\n",
       "      <td>0.023</td>\n",
       "      <td>15.432</td>\n",
       "      <td>1.098</td>\n",
       "      <td>7.792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.050</td>\n",
       "      <td>0.026</td>\n",
       "      <td>12.564</td>\n",
       "      <td>1.085</td>\n",
       "      <td>7.716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.047</td>\n",
       "      <td>0.025</td>\n",
       "      <td>14.898</td>\n",
       "      <td>1.066</td>\n",
       "      <td>7.661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.048</td>\n",
       "      <td>0.024</td>\n",
       "      <td>12.785</td>\n",
       "      <td>1.039</td>\n",
       "      <td>7.780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_loading  image_preprocessing  keypoint_mask_generation  \\\n",
       "0          0.070                0.023                    13.368   \n",
       "1          0.047                0.023                    13.514   \n",
       "2          0.047                0.022                    16.543   \n",
       "3          0.055                0.025                    14.877   \n",
       "4          0.047                0.022                    16.047   \n",
       "5          0.047                0.022                    13.458   \n",
       "6          0.054                0.023                    15.432   \n",
       "7          0.050                0.026                    12.564   \n",
       "8          0.047                0.025                    14.898   \n",
       "9          0.048                0.024                    12.785   \n",
       "\n",
       "   densepose_inference  image_generation  final_image_processing   total  \n",
       "0                1.042             7.678                     0.0  22.184  \n",
       "1                1.062             7.665                     0.0  22.312  \n",
       "2                1.102             7.809                     0.0  25.524  \n",
       "3                1.130             7.728                     0.0  23.817  \n",
       "4                1.051             7.671                     0.0  24.839  \n",
       "5                1.147             7.806                     0.0  22.482  \n",
       "6                1.098             7.792                     0.0  24.399  \n",
       "7                1.085             7.716                     0.0  21.442  \n",
       "8                1.066             7.661                     0.0  23.697  \n",
       "9                1.039             7.780                     0.0  21.676  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3784526e-599e-4646-b03e-d315971d87be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"execution_times_a100.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3348c4f7-3fc9-4e3f-b777-32c94cef8318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images_as_batch(dicts, garm_imgs, garment_des_list, is_checked, is_checked_crop, denoise_steps, seed):\n",
    "    openpose_model.preprocessor.body_estimation.model.to(device)\n",
    "    pipe.to(device)\n",
    "    pipe.unet_encoder.to(device)\n",
    "\n",
    "    human_imgs = []\n",
    "    masks = []\n",
    "    human_imgs_orig = []\n",
    "    pose_imgs = []\n",
    "\n",
    "    for i in range(len(dicts)):\n",
    "        garm_img = garm_imgs[i].convert(\"RGB\").resize((768, 1024))\n",
    "        human_img_orig = dicts[i].convert(\"RGB\")\n",
    "\n",
    "        if is_checked_crop:\n",
    "            width, height = human_img_orig.size\n",
    "            target_width = int(min(width, height * (3 / 4)))\n",
    "            target_height = int(min(height, width * (4 / 3)))\n",
    "            left = (width - target_width) / 2\n",
    "            top = (height - target_height) / 2\n",
    "            right = (width + target_width) / 2\n",
    "            bottom = (height + target_height) / 2\n",
    "            cropped_img = human_img_orig.crop((left, top, right, bottom))\n",
    "            crop_size = cropped_img.size\n",
    "            human_img = cropped_img.resize((768, 1024))\n",
    "        else:\n",
    "            human_img = human_img_orig.resize((768, 1024))\n",
    "\n",
    "        if is_checked:\n",
    "            keypoints = openpose_model(human_img.resize((384, 512)))\n",
    "            model_parse, _ = parsing_model(human_img.resize((384, 512)))\n",
    "            mask, mask_gray = get_mask_location('hd', \"upper_body\", model_parse, keypoints)\n",
    "            mask = mask.resize((768, 1024))\n",
    "        else:\n",
    "            mask = pil_to_binary_mask(dicts[i]['layers'][0].convert(\"RGB\").resize((768, 1024)))\n",
    "\n",
    "        mask_gray = (1 - transforms.ToTensor()(mask)) * tensor_transfrom(human_img)\n",
    "        mask_gray = to_pil_image((mask_gray + 1.0) / 2.0)\n",
    "\n",
    "        human_img_arg = _apply_exif_orientation(human_img.resize((384, 512)))\n",
    "        human_img_arg = convert_PIL_to_numpy(human_img_arg, format=\"BGR\")\n",
    "\n",
    "        args = apply_net.create_argument_parser().parse_args(('show', './configs/densepose_rcnn_R_50_FPN_s1x.yaml', './ckpt/densepose/model_final_162be9.pkl', 'dp_segm', '-v', '--opts', 'MODEL.DEVICE', 'cuda'))\n",
    "        pose_img = args.func(args, human_img_arg)\n",
    "        pose_img = pose_img[:, :, ::-1]\n",
    "        pose_img = Image.fromarray(pose_img).resize((768, 1024))\n",
    "\n",
    "        human_imgs.append(human_img)\n",
    "        masks.append(mask)\n",
    "        human_imgs_orig.append(human_img_orig)\n",
    "        pose_imgs.append(pose_img)  # Adding pose_img to the list\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast():\n",
    "            with torch.no_grad():\n",
    "                prompts = [f\"model is wearing \"] * len(dicts)\n",
    "                negative_prompts = [\"monochrome, lowres, bad anatomy, worst quality, low quality\"] * len(dicts)\n",
    "                with torch.inference_mode():\n",
    "                    (\n",
    "                        prompt_embeds,\n",
    "                        negative_prompt_embeds,\n",
    "                        pooled_prompt_embeds,\n",
    "                        negative_pooled_prompt_embeds,\n",
    "                    ) = pipe.encode_prompt(\n",
    "                        prompts,\n",
    "                        num_images_per_prompt=1,\n",
    "                        do_classifier_free_guidance=True,\n",
    "                        negative_prompt=negative_prompts,\n",
    "                    )\n",
    "\n",
    "                    prompt_embeds_c_list = []\n",
    "                    #for garment_des in garment_des_list:\n",
    "                    prompt = [\"a photo of \"] * len(garment_des_list)\n",
    "                    negative_prompt = [\"monochrome, lowres, bad anatomy, worst quality, low quality\"] * len(garment_des_list)\n",
    "                    if not isinstance(prompt, list):\n",
    "                        prompt = [prompt] * 1\n",
    "                    if not isinstance(negative_prompt, list):\n",
    "                        negative_prompt = [negative_prompt] * 1\n",
    "                    with torch.inference_mode():\n",
    "                        (\n",
    "                            prompt_embeds_c,\n",
    "                            _,\n",
    "                            _,\n",
    "                            _,\n",
    "                        ) = pipe.encode_prompt(\n",
    "                            prompt,\n",
    "                            num_images_per_prompt=1,\n",
    "                            do_classifier_free_guidance=False,\n",
    "                            negative_prompt=negative_prompt,\n",
    "                        )\n",
    "                        #prompt_embeds_c_list.append(prompt_embeds_c)\n",
    "\n",
    "                    pose_imgs_tensors = torch.stack([tensor_transfrom(pose_img) for pose_img in pose_imgs]).to(device, torch.float16)\n",
    "                    garm_tensors = torch.stack([tensor_transfrom(garm_img) for garm_img in garm_imgs]).to(device, torch.float16)\n",
    "                    generators = [torch.Generator(device).manual_seed(seed) if seed is not None else None for _ in range(len(dicts))]\n",
    "                    images = pipe(\n",
    "                        prompt_embeds=prompt_embeds,  # Concatenating along the first dimension\n",
    "                        negative_prompt_embeds=negative_prompt_embeds.to(device, torch.float16),  # Concatenating along the first dimension\n",
    "                        pooled_prompt_embeds=pooled_prompt_embeds.to(device, torch.float16),  # Concatenating along the first dimension\n",
    "                        negative_pooled_prompt_embeds=negative_pooled_prompt_embeds.to(device, torch.float16),  # Concatenating along the first dimension\n",
    "                        num_inference_steps=denoise_steps,\n",
    "                        generator=generators,\n",
    "                        strength=1.0,\n",
    "                        pose_img=pose_imgs_tensors,  # Pass the pose_imgs tensor here\n",
    "                        text_embeds_cloth=prompt_embeds_c.to(device, torch.float16),  # Concatenating along the first dimension\n",
    "                        cloth=garm_tensors,\n",
    "                        mask_image=masks,\n",
    "                        image=human_imgs,\n",
    "                        height=1024,\n",
    "                        width=768,\n",
    "                        ip_adapter_image=garm_imgs,\n",
    "                        guidance_scale=2.0,\n",
    "                    )[0]\n",
    "\n",
    "    return images, masks\n",
    "\n",
    "def start_tryon_batch(dicts, garm_imgs, garment_des, is_checked, is_checked_crop, denoise_steps, seed):\n",
    "    results = process_images_as_batch(dicts, garm_imgs, garment_des, is_checked, is_checked_crop, denoise_steps, seed)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f76919ce-ca50-44ae-a81a-3df9997f15b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.32s/it]\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.41s/it]\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.45s/it]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.11s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55857548c1974aa9a588a7c55c94ecf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 43.15043640136719 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "batch_size = 2\n",
    "start_time = time.time()\n",
    "human_imgs = [Image.open(\"gradio_demo/example/human/foto_mia.jpg\") for i in range(batch_size)]\n",
    "garm_imgs = [Image.open(\"gradio_demo/example/cloth/09163_00.jpg\") for i in range(batch_size)]\n",
    "descs = [\"\" for i in range(batch_size)]\n",
    "out = start_tryon_batch(human_imgs, garm_imgs, descs, True, False, 30, 23)\n",
    "total_time = time.time() - start_time\n",
    "print(\"--- %s seconds ---\" % (total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97b421a-f068-4335-b849-c241e8528399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
